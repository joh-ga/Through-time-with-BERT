{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating BERT Embeddings with bert-as-service\n",
    "See: https://bert-as-service.readthedocs.io/en/latest/  \n",
    "See: https://github.com/hanxiao/bert-as-service"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bert-serving-start -device_map 4 5 -model_dir /media/data/models/bert/tf/uncased_L-12_H-768_A-12 -num_worker=2 -pooling_strategy NONE -max_seq_len NONE -show_tokens_to_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build connection to service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BertClient(ip='136.199.93.84') #remote server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query directory of the model from the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/data/models/bert/tf/uncased_L-12_H-768_A-12'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.server_status['model_dir'] #folder path of the pre-trained BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the sentence embeddings<br>\n",
    "##### *Code snippet 1*: To read corpus file 1 with output file in \"tense: sentence\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path1 = '../data/Sentences_GPT3.txt'\n",
    "\n",
    "with open(dir_path1) as in_file:\n",
    "    s_list = [line.strip() for line in in_file if line.strip()]\n",
    "    tense_list, sent_list = map(list, zip(*(s.split(':') for s in s_list)))\n",
    "    #print(sent_list)\n",
    "    for s in sent_list:\n",
    "        sent_list[sent_list.index(s)] = s.strip()\n",
    "all_embs1 = bc.encode(sent_list, show_tokens = True, is_tokenized = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.21367194,  0.08240603, -0.06714838, ..., -0.53888416,\n",
       "          0.19486403,  0.7237248 ],\n",
       "        [ 0.6012578 , -0.32839608,  0.52842516, ..., -0.13718466,\n",
       "          0.4736324 , -0.43120793],\n",
       "        [ 0.18514141,  0.22976695,  0.22050108, ..., -0.3623354 ,\n",
       "         -0.3686014 , -0.06571554],\n",
       "        ...,\n",
       "        [-0.        , -0.        ,  0.        , ..., -0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        , -0.        ,  0.        , ..., -0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        , -0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.4665227 ,  0.28267437,  0.25747856, ..., -0.32307202,\n",
       "          0.17133777,  0.29996264],\n",
       "        [ 0.75914913, -0.1126898 ,  0.71379143, ..., -0.05284319,\n",
       "          0.7888655 , -0.52549255],\n",
       "        [ 0.16767925, -0.1699537 ,  0.09485049, ..., -0.30874577,\n",
       "          0.17867729,  0.61325   ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         -0.        , -0.        ],\n",
       "        [ 0.        , -0.        ,  0.        , ..., -0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        , -0.        ,  0.        , ..., -0.        ,\n",
       "         -0.        , -0.        ]],\n",
       "\n",
       "       [[ 0.14474693, -0.08975372, -0.06661343, ..., -0.33884603,\n",
       "          0.41859883,  0.3814991 ],\n",
       "        [ 0.7538368 , -0.2202487 ,  0.2984678 , ...,  0.35989192,\n",
       "          0.9651475 , -0.5556381 ],\n",
       "        [ 0.728413  ,  0.40018603, -0.3710153 , ..., -0.79491687,\n",
       "          0.5881246 ,  0.29976833],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        , -0.        ],\n",
       "        [ 0.        , -0.        , -0.        , ..., -0.        ,\n",
       "          0.        , -0.        ],\n",
       "        [ 0.        , -0.        ,  0.        , ...,  0.        ,\n",
       "          0.        , -0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.17087413, -0.34210348,  0.05578066, ..., -0.6305234 ,\n",
       "         -0.09419112,  0.20081055],\n",
       "        [ 0.6923236 , -1.7097616 ,  0.22127587, ..., -0.9964862 ,\n",
       "          0.24769856, -0.07114106],\n",
       "        [ 0.23706822, -0.9427247 ,  0.21894434, ..., -0.6283572 ,\n",
       "          0.2727664 , -0.45725277],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.10654904, -0.40624523, -0.13122906, ..., -0.515131  ,\n",
       "          0.01344988,  0.06779286],\n",
       "        [ 0.6166447 , -1.3177372 ,  0.24001707, ..., -0.8673775 ,\n",
       "          0.0749516 , -0.3381247 ],\n",
       "        [ 0.42211428, -0.6924416 ,  0.10127021, ..., -0.6281364 ,\n",
       "          0.4499238 , -0.7411477 ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.06971456, -0.4751994 , -0.05368862, ..., -0.5139774 ,\n",
       "         -0.01854336,  0.01658032],\n",
       "        [ 0.43711647, -1.7663314 ,  0.10944945, ..., -0.90722805,\n",
       "          0.08818741, -0.2552221 ],\n",
       "        [ 0.42922723, -0.6894525 ,  0.15889417, ..., -0.3451221 ,\n",
       "          0.61567473, -0.63016194],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Code snippet 2*: To read corpus file 2 with output format in \"sentence\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_path2 = '../data/adverbSentences.txt'\n",
    "\n",
    "with open(dir_path2, 'r') as in_file:\n",
    "    sentence_list = [line.strip() for line in in_file if line.strip()]\n",
    "    #print(sentence_list)\n",
    "all_embs2 = bc.encode(sentence_list, show_tokens = True, is_tokenized = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.35714322, -0.04401983,  0.14798854, ..., -0.4364102 ,\n",
       "          0.2483384 ,  0.3197378 ],\n",
       "        [ 0.74051636,  0.36328253,  0.38493878, ..., -0.7083721 ,\n",
       "          0.51678586, -0.90824944],\n",
       "        [ 0.6775574 , -0.306359  ,  0.87465936, ..., -0.17938663,\n",
       "          0.85302895, -0.59072936],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.22477609, -0.28845   , -0.39357919, ..., -0.23550169,\n",
       "          0.14343336,  0.13852412],\n",
       "        [ 0.10404697,  0.24688396, -0.6048023 , ..., -0.75887746,\n",
       "          0.37205458, -1.2569041 ],\n",
       "        [ 0.2544256 , -0.40743682, -0.08173469, ..., -0.06801052,\n",
       "          0.98727196, -0.7952623 ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.19714902, -0.03777267, -0.15490454, ..., -0.38625726,\n",
       "          0.22056442,  0.16556564],\n",
       "        [ 0.5287076 ,  0.4955527 , -0.24758618, ..., -0.7715886 ,\n",
       "          0.5771286 , -1.1220084 ],\n",
       "        [ 0.45096067, -0.21536927,  0.2612296 , ..., -0.20846346,\n",
       "          1.1507875 , -0.56335664],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.1121818 , -0.6385875 ,  0.13402906, ..., -0.51639605,\n",
       "         -0.09431284,  0.08312178],\n",
       "        [ 0.0134624 , -0.7341857 ,  0.25133097, ..., -1.6499207 ,\n",
       "          0.64299023,  0.03427608],\n",
       "        [-0.7258569 , -0.50434595,  0.56058586, ..., -0.4839089 ,\n",
       "         -0.00676914, -0.85187495],\n",
       "        ...,\n",
       "        [ 0.        , -0.        ,  0.        , ..., -0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.58251405, -0.32203776,  0.2833592 , ..., -0.28322408,\n",
       "          0.11768531,  0.3633976 ],\n",
       "        [-0.46015266, -1.14731   ,  1.0302634 , ..., -1.3222969 ,\n",
       "          0.9951428 ,  0.745684  ],\n",
       "        [-0.02133193, -1.4423925 ,  1.0918213 , ..., -1.2480019 ,\n",
       "          0.8317752 , -0.14324433],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.        ,\n",
       "         -0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.29532003, -0.19409195,  0.2805394 , ..., -0.28211328,\n",
       "         -0.02090653,  0.35960492],\n",
       "        [-0.5939955 , -0.6840796 ,  0.67652774, ..., -1.3775909 ,\n",
       "          0.9613397 ,  0.87647605],\n",
       "        [ 0.75865763, -0.8337513 ,  0.803665  , ..., -1.3584907 ,\n",
       "          0.09579781, -1.5327834 ],\n",
       "        ...,\n",
       "        [ 0.        , -0.        ,  0.        , ...,  0.        ,\n",
       "         -0.        , -0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization in the embedding projector Tensorboard\n",
    "See: https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin <br>\n",
    "The embeddings must be uploaded in the form of TSV files (metadata & vectors). <br>\n",
    "*Code snippet 1*: Creating TSV files for corpus without adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# tensors: embeddings\n",
    "with open('../data/tensors.tsv', 'w') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "    #for i in enumerate(all_embs1):\n",
    "    i = 0\n",
    "    while i < len(all_embs1[0]):\n",
    "            writer.writerow(all_embs1[0][i][0])\n",
    "            i += 1\n",
    "\n",
    "# metadata: sentences\n",
    "with open('../data/metadata.tsv', 'w') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "    writer.writerow([\"Id\", \"Tense\", \"Sentence\"])\n",
    "    i = 0\n",
    "    count = 1\n",
    "    while i < len(tense_list):\n",
    "        writer.writerow([int(count), tense_list[i], sent_list[i]])\n",
    "        i += 1\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Code snippet 2*: Creatinf TSV files for corpus with adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tensorsAdverb.tsv', 'w') as tsvfile:  #embeddings\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "    #for i in enumerate(all_embs1):\n",
    "    i = 0\n",
    "    while i < len(all_embs2[0]):\n",
    "            writer.writerow(all_embs2[0][i][0])\n",
    "            i += 1\n",
    "            \n",
    "with open('metadataAdverb.tsv', 'w') as tsvfile: #Sätze\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "    writer.writerow([\"Id\", \"Tense\", \"Sentence\"])\n",
    "    i = 0\n",
    "    count = 1\n",
    "    while i < len(tense_list):\n",
    "        writer.writerow([int(count), tense_list[i], sentence_list[i]]) #Schreibt Tense und Sentence neben einander\n",
    "        i += 1\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
